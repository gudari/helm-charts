# The base hadoop image to use for all components.
# See this repo for image build details: https://github.com/Comcast/kube-yarn/tree/master/image
enabled: true
image:
  repository: gudari/flink-sql-gateway
  tag: 1.12.1-arm64
  pullPolicy: Always #Always

# The version of the hadoop libraries being used in the image.
cmakVersion: 1.12.1

resources:
  requests:
    memory: "1Gi"
    cpu: "300m"
  limits:
    memory: "1Gi"
    cpu: "320m"

config:
  FLINK_CONF_YAML_jobmanager_rpc_address: rpi-flink-flink-jobmanager-0.rpi-flink-flink-jobmanager.rpi-flink.svc.cluster.local
  FLINK_CONF_YAML_jobmanager_rpc_port: "6123"
  FLINK_CONF_YAML_jobmanager_rest_address: flink.gudari.io
  FLINK_CONF_YAML_jobmanager_heap_size: 1024m
  FLINK_CONF_YAML_taskmanager_memory_process_size: 1568m
  FLINK_CONF_YAML_taskmanager_numberOfTaskSlots: "5"
  FLINK_CONF_YAML_parallelism_default: "1"
  FLINK_CONF_YAML_jobmanager_execution_failover___strategy: region
  FLINK_CONF_YAML_taskmanager_data_port: "36300"
  HADOOP_CLUSTER_NAME: 'local'

  # CORE configurations
  CORE_CONF_fs_defaultFS: hdfs://rpi-hadoop-hadoop-hdfs-namenode-0.rpi-hadoop-hadoop-hdfs-namenode.rpi-hadoop.svc.cluster.local:8020
  CORE_CONF_hadoop_http_staticuser_user: root
  CORE_CONF_hadoop_proxyuser_hue_hosts: "\'*\'"
  CORE_CONF_hadoop_proxyuser_hue_groups: "\'*\'"
  CORE_CONF_hadoop_proxyuser_root_hosts: "\'*\'"
  CORE_CONF_hadoop_proxyuser_root_groups: "\'*\'"
  CORE_CONF_hadoop_proxyuser_admin_hosts: "\'*\'"
  CORE_CONF_hadoop_proxyuser_admin_groups: "\'*\'"

  # HDFS configurations
  HDFS_CONF_dfs_namenode_name_dir: file:///hadoop/dfs/name
  HDFS_CONF_dfs_datanode_data_dir: file:///hadoop/dfs/data
  HDFS_CONF_dfs_webhdfs_enabled: "\"true\""
  HDFS_CONF_dfs_permissions_enabled: "\"false\""
  HDFS_CONF_dfs_datanode_use_datanode_hostname: "\"false\""
  HDFS_CONF_dfs_client_use_datanode_hostname: "\"false\""
  HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check: "\"false\""
  HDFS_CONF_dfs_datanode_http_address: "0.0.0.0:50075"
  HDFS_CONF_dfs_namenode_http___address: "0.0.0.0:50070"

  # HIVE configurations
  HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName: 'org.postgresql.Driver'
  HIVE_SITE_CONF_javax_jdo_option_ConnectionURL: 'jdbc:postgresql://rpi-hive-postgresql:5432/hive?createDatabaseIfNotExist=true'
  HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName: hive
  HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword: hive123
  HIVE_SITE_CONF_hive_metastore_warehouse_dir: "hdfs://rpi-hadoop-hadoop-hdfs-namenode-0.rpi-hadoop-hadoop-hdfs-namenode.rpi-hadoop.svc.cluster.local:8020/user/hive/warehouse"
  HIVE_SITE_CONF_hive_metastore_uris: "thrift://rpi-hive-hive-metastore-0.rpi-hive-hive-metastore.rpi-hive.svc.cluster.local:9083"
  HIVE_SITE_CONF_hive_metastore_schema_verification: "\"true\""
  HIVE_SITE_CONF_datanucleus_autoCreateSchema: "\"true\""
  HIVE_SITE_CONF_datanucleus_fixedDatastore: "\"true\""

# Select antiAffinity as either hard or soft, default is soft
antiAffinity: "soft"
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
          - key: "kubernetes.io/hostname"
            operator: In
            values:
            - "rpi-slave-1"
